<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EZIGen: Enhancing zero-shot subject-driven image generation with precise encoding and decoupled guidance">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EZIGen Demo</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/cool.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://zichengduan.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body" style="padding-top: 12px; padding-bottom: 24px;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0; margin-left: 0; margin-right: 0">EZIGen: Enhancing zero-shot subject-driven image generation with precise subject encoding and decoupled guidance</h2>
          <h2 class="title is-2 publication-title" style="margin-top: 0"></h2>
          <h2 class="title is-4 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">arXiv preprint</h2>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zichengduan.github.io/">Zicheng Duan</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;

            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=uOii3uEAAAAJ">Yuxuan Ding</a><sup>2</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;

            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=tlhShPsAAAAJ&hl=en">Chenhui Gou</a><sup>3</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;

            <span class="author-block">
              <a href="https://www.linkedin.com/in/ziqin-zhou-6408051b0/?originalSubdomain=au">Ziqin Zhou</a><sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <br>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/ethan-smith-0b4937196">Ethan Smith</a><sup>4</sup>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;

            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=Y2xu62UAAAAJ">Lingqiao Liu*</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Australian Institute of Machine Learning, University of Adelaide</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Xidian University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <br>
            <span class="author-block"><sup>3</sup>Monash University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>4</sup>Leonardo.AI</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="http://arxiv.org/abs/2409.08091" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16 fa-lg" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <!-- <h2 class="title is-3" style="text-align: center;">Result Demonstration</h2> -->
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div style="text-align: center;">
        <img src="static/images/first3.jpg"
                 class="teaser"
                 alt="Interpolate start reference image." width="90%"/>
      </div>
      
    </div>
    <h2 class="subtitle has-text-centered">
      <span class="method-name">TL;DR: EZIGen enhances zero-shot subject driven generation by integrating a carefully designed Reference UNet extractor and decoupled guidances, preserving subject identity while maintaining flexibilities.
    </h2>
  </div>
</section>


<br>
<br>
<br>


<section class="hero teaser">
  <div class="container">
    <div class="scaled-container" style="overflow: hidden;">
      <div class="scale-up">
        <div class="hero-body is-flex is-justify-content-space-around">
          <video id="teaser1" autoplay controls muted loop playsinline width="33%">
            <source src="static/videos/generation.mp4" type="video/mp4">
          </video>
          <video id="teaser1" autoplay controls muted loop playsinline width="33%">
            <source src="static/videos/editing.mp4" type="video/mp4">
          </video>
          <video id="teaser1" autoplay controls muted loop playsinline width="33%">
            <source src="static/videos/interpolation.mp4" type="video/mp4">
          </video>
        </div>
        
      </div>
    </div>
  </div>
</section>

<br>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Zero-shot subject-driven image generation aims to produce images that incorporate a subject from a given example image. The challenge lies in preserving the subject's identity while aligning with the text prompt, which often requires modifying certain aspects of the subject's appearance. Despite advancements in diffusion model based methods, existing approaches still struggle to balance identity preservation with text prompt alignment. In this study, we conducted an in-depth investigation into this issue and uncovered key insights for achieving effective identity preservation while maintaining a strong balance. Our key findings include: (1) the design of the subject image encoder significantly impacts identity preservation quality, and (2) generating an initial layout is crucial for both text alignment and identity preservation. Building on these insights, we introduce a new approach called EZIGen, which employs two main strategies: a carefully crafted subject image Encoder based on the UNet architecture of the pretrained Stable Diffusion model to ensure high-quality identity transfer, following a process that decouples the guidance stages and iteratively refines the initial image layout. Through these strategies, EZIGen achieves state-of-the-art results on multiple subject-driven benchmarks with a unified model and 100 times less training data.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" style="padding-top: 0px; padding-bottom: 0px;">
  <div class="container is-max-desktop">
    <div class="column is-centered " style="padding-left: 0px; padding-right: 0px;">
      <div class="column is-full-width" style="padding-left: 0px; padding-right: 0px;">
      <div class="content has-text-justified">
        <div style="text-align: center;">
          <h2 class="title is-3">Method</h2>
        </div>
        <div style="text-align: center;">
          <img src="static/images/main3.png"
          class="body"
          alt="Interpolate start reference image. " width="100%"/>
        </div>
        <p>Illustration of the proposed system. Starting from Encoding and Injecting subject feature, where we extract a set of intermediate latent features during the simulated late denoising process of the given noisy subject image using our fixed Reference UNet, we then regard these features as offline Subject Guidance and inject it to the Main UNet via a learnable adapter. Then we showcase how we decouple the generation process into the Layout Generation Process and Appearance Transfer Process. We first leverage the text prompt as Text Guidance using the original text-guided diffusion process to obtain a layout latent at a middle timestep <i>t</i>, then we incorporate the offline Subject Guidance to transfer the subject appearance into the layout latent in the rest of the timesteps. Finally, to achieve a complete transfer, we develop the Iterative Appearance Transfer mechanism to repeat the Appearance Transfer Process by adding noise to the generated image, which continues to repeat for <i>N</i> times until satisfaction.</p>
      </div>
      </div>
      </div>
      </div>

</section>


<section class="section">
  <div class="container is-max-desktop">
  <div class="column is-centered " style="padding-left: 0px; padding-right: 0px;">
    <div class="column is-full-width" style="padding-left: 0px; padding-right: 0px;">
    <div class="content has-text-justified">
      <div style="text-align: center;">
        <h2 class="title is-3">Comparisons</h2>
      </div>
      
      <p>We conduct in-depth comparisons of our method against previous literatures on various tasks: namely subject-driven image generation, subject-driven image editing and human content generation task.</p>
    </div>
    </div>
    </div>
    </div>
  </div>

  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Results on DreamBench dataset </h3>
          <div style="text-align: center;">
            <img src="static/images/qualitative_comparison.jpg"
            class="body"
            alt="Interpolate start reference image. " width="100%"/>
          </div>
          <p>
            Our design showcase astonishing subjects identity preservation abilities without sacrificing text prompt adhearance, outperforms all previous competitors.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Results on DreamEdit dataset</h3>
          <div style="text-align: center;">
            <img src="static/images/compare_edit_qualitative.jpg"
                 class="body"
                 alt="Interpolate start reference image."
                 width="100%"/>
          </div>
          <p>
            Our method is naturally a subject-driven editor when equipped with a foreground/background mask and image inversion, and it demonstrates outstanding performance on the DreamEditBench dataset.
          </p>
        </div>
      </div>
    </div>
    
    

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Results on FastComposer benchmark</h3>
          <div style="text-align: center;">
            <img src="static/images/fastcomposer.png"
                 class="body"
                 alt="Interpolate start reference image."
                 width="100%"/>
          </div>
          <p>
            Due to the high-quality feature extraction and decoupled generation technique, our method produces high-quality human face images with versatilities, <b><i>WITHOUT</i></b> training on domain-specific or large-scale datasets.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Subjects Interpolation</h2>

        <!-- Interpolating. -->
        <div class="content has-text-justified">
          <p>
            Based on the nature of iterative generation, our methods automatically interpolate between when using image during subject-driven editing.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="interpolation-video-column-1">
            <div id="interpolation-image-wrapper-1" >
              Loading 1...
            </div>
            <input class="slider-1 is-fullwidth is-hcentered is-large is-info"
                   id="interpolation-slider-1"
                   step="1" min="0" max="100" value="0" type="range">
          </div>

          <div class="interpolation-video-column-2">
            <div id="interpolation-image-wrapper-2" >
              Loading 2...
            </div>
            <input class="slider-2 is-hcentered is-large is-info"
                   id="interpolation-slider-2"
                   step="1" min="0" max="100" value="0" type="range">
          </div>


        </div>
        <br/>

      </div>
    </div>

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <div style="text-align: center;"><h2 class="title is-3">More Visualization Results</h2></div>
          <h3 class="title is-4">Subject-Driven Generation</h2>
            <img src="static/images/more_results.png"
            class="body"
            alt="Interpolate start reference image." width="100%"/>
          <!-- <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p> -->

          <h3 class="title is-4">Subject-Driven Editing</h2>
            <img src="static/images/more_edit.png"
            class="body"
            alt="Interpolate start reference image." width="100%"/>
          <!-- <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p> -->

          <h3 class="title is-4">Human Content Generation</h2>
            <img src="static/images/more_human.png"
            class="body"
            alt="Interpolate start reference image." width="100%"/>
          <!-- <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p> -->
        </div>
      </div>
    </div>


  </div>
</section>

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<div class="content has-text-centered">
  <script type='text/javascript' src='https://www.freevisitorcounters.com/auth.php?id=08bc533cfc247ea177ea6a414fd04fc0838daa3a'></script>
  <script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/1232035/t/3"></script>
  </div>
</body>
</html>
